{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e685ef-6c3d-4e56-94e3-7e59591eb084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# Library\n",
    "# ==================\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from contextlib import contextmanager\n",
    "import logging\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score,average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,GroupKFold,StratifiedGroupKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder\n",
    "from torch.nn import TransformerDecoder\n",
    "from torch.nn import LayerNorm\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import gc\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline\n",
    "sys.path.append(\"../src/\")\n",
    "from logger import setup_logger, LOGGER\n",
    "from util_tool import reduce_mem_usage\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f18d38-6121-4855-91b9-3e0f32f5b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================\n",
    "# Settings\n",
    "# ===================\n",
    "debug = False\n",
    "ex = \"153\"\n",
    "if not os.path.exists(f\"../output/exp/ex{ex}\"):\n",
    "    os.makedirs(f\"../output/exp/ex{ex}\")\n",
    "    os.makedirs(f\"../output/exp/ex{ex}/ex{ex}_model\")\n",
    "logger_path = f\"../output/exp/ex{ex}/ex_{ex}.txt\"\n",
    "model_path =f\"../output/exp/ex{ex}/ex{ex}_model/ex{ex}.pth\"\n",
    "# config\n",
    "seed = 0\n",
    "shuffle = True\n",
    "n_splits = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model config\n",
    "batch_size = 24\n",
    "n_epochs = 15\n",
    "lr = 1e-3\n",
    "weight_decay = 0.05\n",
    "num_warmup_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f0a11b-7308-4faa-bf83-6b898677d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# data\n",
    "# =====================\n",
    "seq_len = 15000\n",
    "id_path = f\"../output/fe/fe074/fe074_id.parquet\"\n",
    "numerical_path = f\"../output/fe/fe074/fe074_num_array.npy\"\n",
    "target_path = f\"../output/fe/fe074/fe074_target_array.npy\"\n",
    "mask_path = f\"../output/fe/fe074/fe074_mask_array.npy\"\n",
    "valid_path = f\"../output/fe/fe074/fe074_valid_array.npy\"\n",
    "pred_use_path = f\"../output/fe/fe074/fe074_pred_use_array.npy\"\n",
    "time_path = f\"../output/fe/fe074/fe074_time_array.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423fc197-1ce2-4db3-b073-17edc1e4465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Function\n",
    "# ====================\n",
    "def preprocess(numerical_array, \n",
    "               mask_array,\n",
    "               valid_array,\n",
    "               ):\n",
    "    \n",
    "    attention_mask = mask_array == 0\n",
    "\n",
    "    return {\n",
    "        'input_data_numerical_array': numerical_array,\n",
    "        'input_data_mask_array': mask_array,\n",
    "        'input_data_valid_array': valid_array,\n",
    "        'attention_mask': attention_mask,\n",
    "    }\n",
    "\n",
    "class FogDataset(Dataset):\n",
    "    def __init__(self, numerical_array, \n",
    "                 mask_array,valid_array,\n",
    "                 train = True, y = None):\n",
    "        self.numerical_array = numerical_array\n",
    "        self.mask_array = mask_array\n",
    "        self.valid_array = valid_array\n",
    "        self.train = train\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.numerical_array)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = preprocess(\n",
    "            self.numerical_array[item],\n",
    "            self.mask_array[item],\n",
    "            self.valid_array[item], \n",
    "            \n",
    "        )\n",
    "\n",
    "        # Return the processed data where the lists are converted to `torch.tensor`s\n",
    "        if self.train : \n",
    "            return {\n",
    "              'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'],dtype=torch.float32),\n",
    "              'input_data_mask_array':torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n",
    "              'input_data_valid_array':torch.tensor(data['input_data_valid_array'], dtype=torch.long),   \n",
    "              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n",
    "              \"y\":torch.tensor(self.y[item], dtype=torch.float32)\n",
    "               }\n",
    "        else:\n",
    "            return {\n",
    "             'input_data_numerical_array': torch.tensor(data['input_data_numerical_array'],dtype=torch.float32),\n",
    "              'input_data_mask_array':torch.tensor(data['input_data_mask_array'], dtype=torch.long),  \n",
    "              'input_data_valid_array':torch.tensor(data['input_data_valid_array'], dtype=torch.long),  \n",
    "              'attention_mask': torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eac9c32-e65d-46e2-ba0c-f140e489e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FogRnnModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, dropout=0.2,\n",
    "        input_numerical_size=9,\n",
    "        numeraical_linear_size = 64,\n",
    "        model_size = 128,\n",
    "        linear_out = 128,\n",
    "        out_size=3):\n",
    "        super(FogRnnModel, self).__init__()\n",
    "        self.numerical_linear  = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        \n",
    "        self.rnn = nn.GRU(numeraical_linear_size, model_size,\n",
    "                            num_layers = 2, \n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.linear_out  = nn.Sequential(\n",
    "                nn.Linear(model_size*2, \n",
    "                          linear_out),\n",
    "                nn.LayerNorm(linear_out),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(linear_out, \n",
    "                          out_size))\n",
    "        self._reinitialize()\n",
    "        \n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'rnn' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "    \n",
    "    def forward(self, numerical_array,\n",
    "                mask_array,\n",
    "                attention_mask):\n",
    "        \n",
    "        numerical_embedding = self.numerical_linear(numerical_array)\n",
    "        output,_ = self.rnn(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output\n",
    "    \n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97d7f8a5-3417-4604-81b7-d0587e98d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:51:00,533 - INFO - logger set up\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield \n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "    \n",
    "setup_logger(out_file=logger_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d00ce8f5-0471-48cb-ad74-dc2c19ade72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# main\n",
    "# ====================\n",
    "df_id = pd.read_parquet(id_path)\n",
    "numerical_array = np.load(numerical_path)\n",
    "target_array = np.load(target_path)\n",
    "mask_array = np.load(mask_path)\n",
    "valid_array = np.load(valid_path)\n",
    "pred_use_array = np.load(pred_use_path)\n",
    "time_array = np.load(time_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2149cf-9036-49d5-b0b6-b3730c15c3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2f9319f58c43d69b7c2131937b1784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:51:45,303 - INFO - [fold 0] done in 44 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea0a92671c74ba59430d60c84f5b016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:52:28,760 - INFO - [fold 1] done in 43 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869ed5b4ae0d40128f454f489cdb820d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:53:11,524 - INFO - [fold 2] done in 43 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5318bae07f44b390ae4d333fb10646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:53:52,114 - INFO - [fold 3] done in 41 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58149d32406f40c680046a6e9eb05d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 11:54:35,767 - INFO - [fold 4] done in 44 s\n",
      "2023-05-29 11:54:35,769 - INFO - [gru] done in 214 s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"gru\"):\n",
    "    set_seed(seed)\n",
    "    for fold in range(5):\n",
    "        with timer(f\"fold {fold}\"):\n",
    "            val_numerical_array = numerical_array.copy()\n",
    "            val_target_array = target_array.copy()\n",
    "            val_mask_array = mask_array.copy()\n",
    "            val_valid_array = valid_array.copy()\n",
    "            val_pred_array = pred_use_array.copy()\n",
    "\n",
    "            val_ = FogDataset(val_numerical_array,\n",
    "                                val_mask_array,\n",
    "                                val_valid_array, \n",
    "                                train=True,\n",
    "                                y=val_target_array)\n",
    "\n",
    "            val_loader = DataLoader(dataset=val_, \n",
    "                                batch_size=batch_size, \n",
    "                                shuffle = False , num_workers=8)\n",
    "\n",
    "            model = FogRnnModel()\n",
    "            model.load_state_dict(torch.load(f\"../output/exp/ex{ex}/ex{ex}_model/ex{ex}_{fold}.pth\"))\n",
    "            model = model.to(device)\n",
    "            model.eval()  # switch model to the evaluation mode\n",
    "            val_preds = np.ndarray((0,seq_len,3))\n",
    "            tk0 = tqdm(val_loader, total=len(val_loader))\n",
    "            with torch.no_grad():  # Do not calculate gradient since we are only predicting\n",
    "                # Predicting on validation set\n",
    "                for d in tk0:\n",
    "                    input_data_numerical_array = d['input_data_numerical_array'].to(device)\n",
    "                    input_data_mask_array = d['input_data_mask_array'].to(device)\n",
    "                    attention_mask = d['attention_mask'].to(device)\n",
    "                    output = model(input_data_numerical_array, \n",
    "                               input_data_mask_array,\n",
    "                               attention_mask)\n",
    "                    val_preds = np.concatenate([val_preds, output.sigmoid().detach().cpu().numpy()], axis=0)\n",
    "            np.save(f\"../output/exp/ex{ex}/ex{ex}_notype_{fold}_oof_{seq_len}.npy\",val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe09515-c96d-4715-a760-1d994376604a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8507fda981094591bc2e6016a3ab02ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4a88e3090d42ea94d1761200f82026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8778eb16163f48d39762538bd6b96b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f21569b89f54cbc852ad88480e238ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9317dcdf5cb3416a871150c87f39ffc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id_array = df_id[\"Id\"].values\n",
    "for i in range(5):\n",
    "    pred_all = []\n",
    "    pred = np.load(f\"../output/exp/ex{ex}/ex{ex}_notype_{i}_oof_{seq_len}.npy\")\n",
    "    for v in tqdm(range(len(pred_use_array))):\n",
    "        use_ = pred_use_array[v,:] == 1\n",
    "        pred_ = pred[v,use_ == 1,:]\n",
    "        time_ = time_array[v,use_ == 1]\n",
    "        Id = id_array[v]\n",
    "        pred_df = pd.DataFrame()\n",
    "        pred_df[\"Time\"] = time_\n",
    "        pred_df[\"Id\"] = Id\n",
    "        pred_df[\"StartHesitation\"] = pred_[:,0]\n",
    "        pred_df[\"Turn\"] = pred_[:,1]\n",
    "        pred_df[\"Walking\"] = pred_[:,2]\n",
    "        pred_all.append(pred_df)\n",
    "    pred_all = pd.concat(pred_all).reset_index(drop=True)\n",
    "    pred_all.to_parquet(f\"../output/exp/ex{ex}/ex{ex}_notype_{i}_pred_{seq_len}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182fa14-c508-47ce-9305-70d65545883a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
