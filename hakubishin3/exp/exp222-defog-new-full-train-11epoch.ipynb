{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fce0c36c-62c8-48ce-a8c4-a1abd85e9649",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fce0c36c-62c8-48ce-a8c4-a1abd85e9649",
    "outputId": "6aba56b1-fb62-402d-a444-5e247d1f748e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 30 23:34:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.129.06   Driver Version: 470.129.06   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:81:00.0 Off |                  N/A |\n",
      "| 41%   31C    P8     9W / 280W |     67MiB / 24219MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa56a35-da16-4781-8766-181cb3b0175c",
   "metadata": {
    "id": "8fa56a35-da16-4781-8766-181cb3b0175c"
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78176554-4c3c-4fcd-b462-f9dc9e6282e8",
   "metadata": {
    "id": "78176554-4c3c-4fcd-b462-f9dc9e6282e8"
   },
   "outputs": [],
   "source": [
    "EXP_NAME = \"pd-exp222\"\n",
    "ENV = \"local\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f8a937-b291-436a-aa7a-181b36a20572",
   "metadata": {
    "id": "10f8a937-b291-436a-aa7a-181b36a20572"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    env = ENV\n",
    "    exp_name = EXP_NAME\n",
    "    debug = DEBUG\n",
    "    input_dir = None\n",
    "    output_dir = None\n",
    "    print_freq = 50\n",
    "    num_workers = 8\n",
    "\n",
    "    # ====================================================\n",
    "    # dataset\n",
    "    # ====================================================\n",
    "    competition_name = \"tlvmc-parkinsons-freezing-gait-prediction\"\n",
    "    target_cols = [\"StartHesitation\", \"Turn\", \"Walking\"]\n",
    "    seq_len = 5000\n",
    "    shift = 2500\n",
    "    offset = 1250\n",
    "\n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    batch_size = 24\n",
    "    epochs = 11\n",
    "    num_warmup_steps = 10\n",
    "\n",
    "    # ====================================================\n",
    "    # optimizer\n",
    "    # ====================================================\n",
    "    lr = 1e-3\n",
    "    weight_decay = 0.05  # default: 0.0\n",
    "\n",
    "    # ====================================================\n",
    "    # cross validation\n",
    "    # ====================================================\n",
    "    seed = 0\n",
    "    n_fold = 5\n",
    "    train_fold = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # ====================================================\n",
    "    # mode settings\n",
    "    # ====================================================\n",
    "    train_by_fold = False\n",
    "    train_all = True\n",
    "    upload_kaggle_dataset = True\n",
    "    inference = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8682060-b820-4c58-aa30-fe4a8cb018a5",
   "metadata": {
    "id": "e8682060-b820-4c58-aa30-fe4a8cb018a5"
   },
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.train_fold = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d20697-18f6-4f70-9bca-ab900cfdf671",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "85d20697-18f6-4f70-9bca-ab900cfdf671",
    "outputId": "66f910e5-4942-4d1b-e2bc-fb6ffb19efe7"
   },
   "outputs": [],
   "source": [
    "if CFG.env == \"colab\" and CFG.upload_kaggle_dataset:\n",
    "    !pip install kaggle\n",
    "    from google.colab import files, drive\n",
    "    uploaded = files.upload()\n",
    "    for fn in uploaded.keys():\n",
    "        print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "            name=fn, length=len(uploaded[fn])))\n",
    "    # Then move kaggle.json into the folder where the API expects to find it.\n",
    "    !mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a121d33-4a47-4ddc-b1fb-13e7e16a2db2",
   "metadata": {
    "id": "2a121d33-4a47-4ddc-b1fb-13e7e16a2db2"
   },
   "source": [
    "# Directory setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2460823-aa94-454a-a24b-a8cee500dcdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2460823-aa94-454a-a24b-a8cee500dcdb",
    "outputId": "975905b6-d0c1-4205-f915-2dd4909a87b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env is local.\n",
      "Requirement already satisfied: polars==0.17.12 in /opt/conda/lib/python3.7/site-packages (0.17.12)\n",
      "Requirement already satisfied: typing_extensions>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from polars==0.17.12) (4.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "print(f\"env is {CFG.env}.\")\n",
    "if CFG.env == \"colab\":\n",
    "    # colab環境\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    input_path = Path(\"./drive/MyDrive/Colab Notebooks/input\")\n",
    "    output_path = Path(\"./drive/MyDrive/Colab Notebooks/output\")\n",
    "    CFG.input_dir = input_path\n",
    "    CFG.output_dir = output_path / CFG.exp_name\n",
    "    output_path_tmp = Path(\"./drive/MyDrive/Colab\\ Notebooks/output\")\n",
    "    CFG.output_dir_tmp = output_path_tmp / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "    !pip install polars==0.17.12\n",
    "    !pip install transformers==4.20.1\n",
    "elif CFG.env == \"local\":\n",
    "    # ローカルサーバ\n",
    "    CFG.input_dir = Path(\"../mnt/input/\")\n",
    "    CFG.output_dir = Path(\"../mnt/output/\") / CFG.exp_name\n",
    "    if not CFG.output_dir.exists():\n",
    "        CFG.output_dir.mkdir()\n",
    "        print(f\"Create dir: {CFG.output_dir}\")\n",
    "    !pip install polars==0.17.12\n",
    "elif CFG.env == \"kaggle\":\n",
    "    # kaggle環境\n",
    "    CFG.input_dir = Path(\"../input/\") / CFG.competition_name\n",
    "    CFG.output_dir = Path(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c706b-477e-46f4-b95f-6db365daaa71",
   "metadata": {
    "id": "c06c706b-477e-46f4-b95f-6db365daaa71"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b4a332-b713-47f5-ad2d-6aa4826c83a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28b4a332-b713-47f5-ad2d-6aa4826c83a2",
    "outputId": "80911a47-0deb-4889-90dd-e28acde3bed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.__version__: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pathlib\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69eca1cd-ab85-4828-b2d2-d3dd4e316084",
   "metadata": {
    "id": "69eca1cd-ab85-4828-b2d2-d3dd4e316084"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7753e967-fad3-4aa7-94fa-b783bba581f8",
   "metadata": {
    "id": "7753e967-fad3-4aa7-94fa-b783bba581f8"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41224cdc-1092-401d-b3fe-9e4a1236e317",
   "metadata": {
    "id": "41224cdc-1092-401d-b3fe-9e4a1236e317"
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d12554b0-22e2-4795-9f17-b6f6c4d6b0e8",
   "metadata": {
    "id": "d12554b0-22e2-4795-9f17-b6f6c4d6b0e8"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdcab2c-db41-4766-ae3e-6ccedd211e3e",
   "metadata": {
    "id": "2cdcab2c-db41-4766-ae3e-6ccedd211e3e"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00155ce1-020a-499c-84e0-1390427d7417",
   "metadata": {
    "id": "00155ce1-020a-499c-84e0-1390427d7417"
   },
   "outputs": [],
   "source": [
    "tdcsfog_metadata = pd.read_csv(CFG.input_dir / \"tdcsfog_metadata.csv\")\n",
    "defog_metadata = pd.read_csv(CFG.input_dir / \"defog_metadata.csv\")\n",
    "subjects = pd.read_csv(CFG.input_dir / \"subjects.csv\")\n",
    "events = pd.read_csv(CFG.input_dir / \"events.csv\")\n",
    "tasks = pd.read_csv(CFG.input_dir / \"tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "o_63ZAHFs6O9",
   "metadata": {
    "id": "o_63ZAHFs6O9"
   },
   "outputs": [],
   "source": [
    "tdcsfog_subject_folds = pd.read_csv(CFG.input_dir / \"tdcsfog_subject_5folds.csv\")\n",
    "defog_subject_folds = pd.read_csv(CFG.input_dir / \"defog_subject_5folds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3f7db-6b2c-40dc-88cf-fcfc3efee497",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3e85a9e-9447-4483-b650-313e7a1bbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "data_list = glob.glob(str(CFG.input_dir / \"train/defog/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f617a59-91bb-49fd-9cd3-1f8ac218a468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16244e27c5cc46af8e5c0ada41f1a36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_array = []\n",
    "target_array = []\n",
    "id_list = []\n",
    "mask_array = []\n",
    "pred_use_array = []\n",
    "time_array = []\n",
    "valid_array = []\n",
    "\n",
    "for i in tqdm(defog_metadata[\"Id\"].values):\n",
    "    path = CFG.input_dir / \"train/defog\" / f\"{i}.csv\"\n",
    "    if str(path) not in data_list:\n",
    "        continue\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    df[\"valid\"] = df[\"Valid\"] & df[\"Task\"]\n",
    "    df[\"valid\"] = df[\"valid\"].astype(int)\n",
    "\n",
    "    # create features\n",
    "    cols = [\"AccV\", \"AccML\", \"AccAP\"]\n",
    "    for c in cols:\n",
    "        df[f\"{c}_lag_diff\"] = df[c].diff()\n",
    "        df[f\"{c}_lead_diff\"] = df[c].diff(-1)\n",
    "\n",
    "    # scaling\n",
    "    num_cols = [\n",
    "        \"AccV\", \"AccML\", \"AccAP\",\n",
    "        \"AccV_lag_diff\", \"AccV_lead_diff\",\n",
    "        \"AccML_lag_diff\", \"AccML_lead_diff\",\n",
    "        \"AccAP_lag_diff\", \"AccAP_lead_diff\",\n",
    "    ]\n",
    "    sc = StandardScaler()\n",
    "    df[num_cols] = sc.fit_transform(df[num_cols].values)\n",
    "    df[num_cols] = df[num_cols].fillna(0)\n",
    "\n",
    "    num = df[num_cols].values\n",
    "    target = df[CFG.target_cols].values\n",
    "    time_values = df[\"Time\"].values\n",
    "    valid = df[\"valid\"].values\n",
    "\n",
    "    batch = (len(df)-1) // CFG.shift\n",
    "    batch = max(1, batch)\n",
    "    num_array_ = np.zeros([batch, CFG.seq_len, len(num_cols)])\n",
    "    target_array_ = np.zeros([batch, CFG.seq_len, len(CFG.target_cols)])\n",
    "    time_array_ = np.zeros([batch, CFG.seq_len], dtype=int)\n",
    "    mask_array_ = np.zeros([batch, CFG.seq_len], dtype=int)\n",
    "    pred_use_array_ = np.zeros([batch, CFG.seq_len], dtype=int)\n",
    "    valid_array_ = np.zeros([batch, CFG.seq_len], dtype=int)\n",
    "\n",
    "    if len(df) <= CFG.seq_len:\n",
    "        num_array_[0, :len(num), :] = num\n",
    "        target_array_[0, :len(target), :] = target\n",
    "        mask_array_[0, :len(target)] = 1\n",
    "        pred_use_array_[0, :len(target)] = 1\n",
    "        time_array_[0, :len(time_values)] = time_values\n",
    "        valid_array_[0, :len(target)] = valid\n",
    "        continue\n",
    "\n",
    "    for n, b in enumerate(range(batch)):\n",
    "        if b == (batch - 1):\n",
    "            # get values\n",
    "            num_ = num[b*CFG.shift:]\n",
    "            target_ = target[b*CFG.shift:]\n",
    "            time_ = time_values[b*CFG.shift:]\n",
    "            valid_ = valid[b*CFG.shift:]\n",
    "            # insert values\n",
    "            num_array_[b, :len(num_), :] = num_\n",
    "            target_array_[b, :len(target_), :] = target_\n",
    "            mask_array_[b, :len(target_)] = 1\n",
    "            pred_use_array_[b, CFG.offset:len(target_)] = 1\n",
    "            time_array_[b, :len(time_)] = time_\n",
    "            valid_array_[b, :len(valid_)] = valid_\n",
    "        elif b == 0:\n",
    "            # get values\n",
    "            num_ = num[0:CFG.seq_len]\n",
    "            target_ = target[0:CFG.seq_len]\n",
    "            time_ = time_values[0:CFG.seq_len]\n",
    "            valid_ = valid[0:CFG.seq_len]\n",
    "            # insert values\n",
    "            num_array_[0, :, :] = num_\n",
    "            target_array_[0, :, :] = target_\n",
    "            mask_array_[0, :] = 1\n",
    "            pred_use_array_[0, :CFG.seq_len-CFG.offset] = 1\n",
    "            time_array_[0, :] = time_\n",
    "            valid_array_[0, :] = valid_\n",
    "        else:\n",
    "            # get values\n",
    "            num_ = num[b*CFG.shift:b*CFG.shift+CFG.seq_len]\n",
    "            target_ = target[b*CFG.shift:b*CFG.shift+CFG.seq_len]\n",
    "            time_ = time_values[b*CFG.shift:b*CFG.shift+CFG.seq_len]\n",
    "            valid_ = valid[b*CFG.shift:b*CFG.shift+CFG.seq_len]\n",
    "            # insert values\n",
    "            num_array_[b, :, :] = num_\n",
    "            target_array_[b, :, :] = target_\n",
    "            mask_array_[b, :] = 1\n",
    "            pred_use_array_[b, CFG.offset:CFG.seq_len-CFG.offset] = 1\n",
    "            time_array_[b, :] = time_\n",
    "            valid_array_[b, :] = valid_\n",
    "\n",
    "    num_array.append(num_array_)\n",
    "    target_array.append(target_array_)\n",
    "    mask_array.append(mask_array_)\n",
    "    pred_use_array.append(pred_use_array_)\n",
    "    time_array.append(time_array_)\n",
    "    valid_array.append(valid_array_)\n",
    "    id_list += [i for _ in range(batch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "681ec878-7870-498e-a46e-dd253ffceb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_array = np.concatenate(num_array, axis=0)\n",
    "target_array = np.concatenate(target_array, axis=0)\n",
    "mask_array = np.concatenate(mask_array, axis=0)\n",
    "pred_use_array = np.concatenate(pred_use_array, axis=0)\n",
    "time_array = np.concatenate(time_array, axis=0)\n",
    "valid_array = np.concatenate(valid_array,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa618d0b-4fcd-41a4-bacf-e14c5f4039b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5369, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id Subject\n",
       "0  02ea782681  ae2d35\n",
       "1  02ea782681  ae2d35\n",
       "2  02ea782681  ae2d35\n",
       "3  02ea782681  ae2d35\n",
       "4  02ea782681  ae2d35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_id = pd.DataFrame()\n",
    "df_id[\"Id\"] = id_list\n",
    "df_id = pd.merge(df_id, defog_metadata[[\"Id\", \"Subject\"]], on=\"Id\", how=\"left\")\n",
    "print(df_id.shape)\n",
    "display(df_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47162bcc-b196-4df3-9ea5-5cf5bad0b136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5369, 5000, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9a162-8909-4afb-866f-d176bcd2db4c",
   "metadata": {
    "id": "31d9a162-8909-4afb-866f-d176bcd2db4c"
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a454d81-797a-43c8-b424-142e377c0290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5369, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02ea782681</td>\n",
       "      <td>ae2d35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id Subject  fold\n",
       "0  02ea782681  ae2d35     0\n",
       "1  02ea782681  ae2d35     0\n",
       "2  02ea782681  ae2d35     0\n",
       "3  02ea782681  ae2d35     0\n",
       "4  02ea782681  ae2d35     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_id = pd.merge(df_id, defog_subject_folds, on=\"Subject\", how=\"left\")\n",
    "print(df_id.shape)\n",
    "display(df_id.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c13daf-ae18-4a77-85a9-15e20a0c69ee",
   "metadata": {
    "id": "24c13daf-ae18-4a77-85a9-15e20a0c69ee"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "yTqfXyk_2v5r",
   "metadata": {
    "id": "yTqfXyk_2v5r"
   },
   "outputs": [],
   "source": [
    "def preprocess(numerical_array, mask_array, valid_array):\n",
    "    attention_mask = mask_array == 0\n",
    "    return {\n",
    "        \"input_data_numerical_array\": numerical_array,\n",
    "        \"input_data_mask_array\": mask_array,\n",
    "        \"input_data_valid_array\": valid_array,\n",
    "        \"attention_mask\": attention_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2fee5be-e3a9-498a-8972-feb495051354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FogDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        numerical_array,\n",
    "        mask_array,\n",
    "        valid_array,\n",
    "        train=True,\n",
    "        y=None,\n",
    "    ):\n",
    "        self.numerical_array = numerical_array\n",
    "        self.mask_array = mask_array\n",
    "        self.valid_array = valid_array\n",
    "        self.train = train\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numerical_array)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = preprocess(\n",
    "            self.numerical_array[item],\n",
    "            self.mask_array[item],\n",
    "            self.valid_array[item],\n",
    "\n",
    "        )\n",
    "\n",
    "        # Return the processed data where the lists are converted to `torch.tensor`s\n",
    "        if self.train:\n",
    "            return {\n",
    "              \"input_data_numerical_array\": torch.tensor(data[\"input_data_numerical_array\"], dtype=torch.float32),\n",
    "              \"input_data_mask_array\": torch.tensor(data[\"input_data_mask_array\"], dtype=torch.long),\n",
    "              \"input_data_valid_array\": torch.tensor(data[\"input_data_valid_array\"], dtype=torch.long),\n",
    "              \"attention_mask\": torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n",
    "              \"y\": torch.tensor(self.y[item], dtype=torch.float32),\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "              \"input_data_numerical_array\": torch.tensor(data[\"input_data_numerical_array\"], dtype=torch.float32),\n",
    "              \"input_data_mask_array\": torch.tensor(data[\"input_data_mask_array\"], dtype=torch.long),\n",
    "              \"input_data_valid_array\": torch.tensor(data[\"input_data_valid_array\"], dtype=torch.long),\n",
    "              \"attention_mask\": torch.tensor(data[\"attention_mask\"], dtype=torch.bool),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087bee5-76c4-48b3-94dd-6bc1a087c255",
   "metadata": {
    "id": "d087bee5-76c4-48b3-94dd-6bc1a087c255"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88ea0ff-5acc-485c-bb69-4559ce260ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FogLstmModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dropout=0.2,\n",
    "        input_numerical_size=9,\n",
    "        numeraical_linear_size=64,\n",
    "        model_size=128,\n",
    "        linear_out=128,\n",
    "        out_size=3,\n",
    "    ):\n",
    "        super(FogLstmModel, self).__init__()\n",
    "        self.numerical_linear = nn.Sequential(\n",
    "                nn.Linear(input_numerical_size, numeraical_linear_size),\n",
    "                nn.LayerNorm(numeraical_linear_size)\n",
    "            )\n",
    "        self.lstm = nn.GRU(\n",
    "            numeraical_linear_size,\n",
    "            model_size,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.linear_out = nn.Sequential(\n",
    "            nn.Linear(model_size*2, linear_out),\n",
    "            nn.LayerNorm(linear_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(linear_out, out_size),\n",
    "        )\n",
    "        self._reinitialize()\n",
    "\n",
    "    def _reinitialize(self):\n",
    "        \"\"\"\n",
    "        Tensorflow/Keras-like initialization\n",
    "        \"\"\"\n",
    "        for name, p in self.named_parameters():\n",
    "            if 'lstm' in name:\n",
    "                if 'weight_ih' in name:\n",
    "                    nn.init.xavier_uniform_(p.data)\n",
    "                elif 'weight_hh' in name:\n",
    "                    nn.init.orthogonal_(p.data)\n",
    "                elif 'bias_ih' in name:\n",
    "                    p.data.fill_(0)\n",
    "                    # Set forget-gate bias to 1\n",
    "                    n = p.size(0)\n",
    "                    p.data[(n // 4):(n // 2)].fill_(1)\n",
    "                elif 'bias_hh' in name:\n",
    "                    p.data.fill_(0)\n",
    "\n",
    "    def forward(self, numerical_array, mask_array, attention_mask):\n",
    "        numerical_embedding = self.numerical_linear(numerical_array)\n",
    "        output, _ = self.lstm(numerical_embedding)\n",
    "        output = self.linear_out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922c5b5-8d77-4cd8-9393-cd40d26e06c5",
   "metadata": {
    "id": "6922c5b5-8d77-4cd8-9393-cd40d26e06c5"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af6d86a7-4a85-4a88-a456-553858204ce4",
   "metadata": {
    "id": "af6d86a7-4a85-4a88-a456-553858204ce4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    train_loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    scheduler,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    start = time.time()\n",
    "    for step, d in enumerate(train_loader):\n",
    "        input_data_numerical_array = d[\"input_data_numerical_array\"].to(device)\n",
    "        input_data_mask_array = d[\"input_data_mask_array\"].to(device)\n",
    "        input_data_valid_array = d[\"input_data_valid_array\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        y = d[\"y\"].to(device)\n",
    "        batch_size = y.size(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input_data_numerical_array, input_data_mask_array, attention_mask)\n",
    "        loss = criterion(output[input_data_valid_array==1], y[input_data_valid_array==1])\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print(\n",
    "                \"Epoch: [{0}][{1}/{2}] \"\n",
    "                \"Elapsed {remain:s} \"\n",
    "                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n",
    "                \"LR: {lr:.6f}  \"\n",
    "                .format(\n",
    "                    epoch+1,\n",
    "                    step,\n",
    "                    len(train_loader),\n",
    "                    remain=timeSince(start, float(step+1) / len(train_loader)),\n",
    "                    loss=losses,\n",
    "                    lr=scheduler.get_lr()[0],\n",
    "                )\n",
    "            )\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc305368-ff2b-46b1-89a7-d7bb6b543b6a",
   "metadata": {
    "id": "dc305368-ff2b-46b1-89a7-d7bb6b543b6a"
   },
   "outputs": [],
   "source": [
    "def valid_fn(\n",
    "    val_loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for d in tqdm(val_loader):\n",
    "        input_data_numerical_array = d[\"input_data_numerical_array\"].to(device)\n",
    "        input_data_mask_array = d[\"input_data_mask_array\"].to(device)\n",
    "        input_data_valid_array = d[\"input_data_valid_array\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_data_numerical_array, input_data_mask_array, attention_mask)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "jNMgA0skD1cW",
   "metadata": {
    "id": "jNMgA0skD1cW"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_idx, valid_idx, i_fold, device):\n",
    "    print(f\"========== fold {i_fold} training ==========\")\n",
    "\n",
    "    train_numerical_array = num_array[train_idx]\n",
    "    train_target_array = target_array[train_idx]\n",
    "    train_mask_array = mask_array[train_idx]\n",
    "    train_valid_array = valid_array[train_idx]\n",
    "\n",
    "    val_numerical_array = num_array[valid_idx]\n",
    "    val_target_array = target_array[valid_idx]\n",
    "    val_mask_array = mask_array[valid_idx]\n",
    "    val_pred_array = pred_use_array[valid_idx]\n",
    "    val_valid_array = valid_array[valid_idx]\n",
    "\n",
    "    train_dataset = FogDataset(\n",
    "        train_numerical_array,\n",
    "        train_mask_array,\n",
    "        train_valid_array,\n",
    "        train=True,\n",
    "        y=train_target_array,\n",
    "    )\n",
    "    val_dataset = FogDataset(\n",
    "        val_numerical_array,\n",
    "        val_mask_array,\n",
    "        val_valid_array,\n",
    "        train=True,\n",
    "        y=val_target_array,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "    )\n",
    "    print(f\"Train Size: {len(train_dataset)}\")\n",
    "    print(f\"Valid Size: {len(val_dataset)}\")\n",
    "\n",
    "    model = FogLstmModel()\n",
    "    model = model.to(device)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "\n",
    "    num_train_optimization_steps = int(len(train_loader) * CFG.epochs)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=CFG.num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    best_score = 0.0\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = train_fn(\n",
    "            train_loader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        val_preds = valid_fn(\n",
    "            val_loader,\n",
    "            model,\n",
    "            criterion,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        # scoring\n",
    "        pred_valid_index = (val_mask_array == 1) & (val_pred_array == 1) & (val_valid_array == 1)\n",
    "        scores = [\n",
    "            average_precision_score(\n",
    "                val_target_array[pred_valid_index][:, i],\n",
    "                val_preds[pred_valid_index][:, i],\n",
    "            )\n",
    "            for i in range(3)\n",
    "        ]\n",
    "        mean_score = np.nanmean(scores)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Fold {i_fold} Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        print(f\"Fold {i_fold} Epoch {epoch+1} - Score: {mean_score:.4f}\")\n",
    "        print(f\"Fold {i_fold} Epoch {epoch+1} - ClassWise Score: {[score for score in scores]}\")\n",
    "\n",
    "        if best_score <= mean_score:\n",
    "            print(f\"Fold {i_fold} Epoch {epoch+1} - Save Best Score: {best_score} -> {mean_score:.4f}\")\n",
    "            best_score = mean_score\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"predictions\": val_preds,\n",
    "                },\n",
    "                CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "            )\n",
    "\n",
    "    val_preds = torch.load(\n",
    "        CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )[\"predictions\"]\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e08583ae-f151-422a-8b06-011e8a5279e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(train_idx, i_fold, device):\n",
    "    print(f\"========== fold {i_fold} training ==========\")\n",
    "\n",
    "    train_numerical_array = num_array[train_idx]\n",
    "    train_target_array = target_array[train_idx]\n",
    "    train_mask_array = mask_array[train_idx]\n",
    "    train_valid_array = valid_array[train_idx]\n",
    "\n",
    "    train_dataset = FogDataset(\n",
    "        train_numerical_array,\n",
    "        train_mask_array,\n",
    "        train_valid_array,\n",
    "        train=True,\n",
    "        y=train_target_array,\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=CFG.num_workers,\n",
    "    )\n",
    "    print(f\"Train Size: {len(train_dataset)}\")\n",
    "\n",
    "    model = FogLstmModel()\n",
    "    model = model.to(device)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": CFG.weight_decay},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=CFG.lr,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "    )\n",
    "\n",
    "    num_train_optimization_steps = int(len(train_loader) * CFG.epochs)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=CFG.num_warmup_steps,\n",
    "        num_training_steps=num_train_optimization_steps,\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        avg_loss = train_fn(\n",
    "            train_loader,\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epoch,\n",
    "            scheduler,\n",
    "            device,\n",
    "        )\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Fold {i_fold} Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s\")\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            },\n",
    "            CFG.output_dir / f\"fold{i_fold}_best.pth\",\n",
    "        )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e26e77eb-25e1-40e1-abd8-d7f84aa1cc0f",
   "metadata": {
    "id": "e26e77eb-25e1-40e1-abd8-d7f84aa1cc0f"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ====================================================\n",
    "    # Training\n",
    "    # ====================================================\n",
    "    y_oof = np.empty([len(target_array), CFG.seq_len, 3])\n",
    "    if CFG.train_by_fold:\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            if i_fold in CFG.train_fold:\n",
    "                train_idx = list(df_id.query(\"fold != @i_fold\").index)\n",
    "                valid_idx = list(df_id.query(\"fold == @i_fold\").index)\n",
    "                best_val_preds = train_loop(train_idx, valid_idx, i_fold, DEVICE)\n",
    "                y_oof[valid_idx] = best_val_preds\n",
    "                np.save(CFG.output_dir / f\"fold{i_fold}_val_preds_{CFG.seq_len}.npy\", best_val_preds)\n",
    "        np.save(CFG.output_dir / f\"oof_{CFG.seq_len}.npy\", y_oof)\n",
    "\n",
    "    if CFG.train_all:\n",
    "        for i_fold in range(CFG.n_fold):\n",
    "            train_idx = list(df_id.index)\n",
    "            train_all(train_idx, i_fold, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8537174-41cf-47b5-81f6-c5ca80a72d9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b8537174-41cf-47b5-81f6-c5ca80a72d9d",
    "outputId": "7d6449b0-d747-43f2-e485-18918f172a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== fold 0 training ==========\n",
      "Train Size: 5369\n",
      "Epoch: [1][0/224] Elapsed 0m 1s (remain 7m 20s) Loss: 0.8165(0.8165) LR: 0.000100  \n",
      "Epoch: [1][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.1982(0.2496) LR: 0.000983  \n",
      "Epoch: [1][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1491(0.2032) LR: 0.000963  \n",
      "Epoch: [1][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0831(0.1882) LR: 0.000943  \n",
      "Epoch: [1][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.1181(0.1752) LR: 0.000922  \n",
      "Epoch: [1][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.2322(0.1726) LR: 0.000913  \n",
      "Fold 0 Epoch 1 - avg_train_loss: 0.1726  time: 123s\n",
      "Epoch: [2][0/224] Elapsed 0m 1s (remain 4m 47s) Loss: 0.1992(0.1992) LR: 0.000912  \n",
      "Epoch: [2][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.2042(0.1294) LR: 0.000892  \n",
      "Epoch: [2][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1133(0.1341) LR: 0.000872  \n",
      "Epoch: [2][150/224] Elapsed 1m 24s (remain 0m 40s) Loss: 0.1302(0.1308) LR: 0.000851  \n",
      "Epoch: [2][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.1326(0.1284) LR: 0.000831  \n",
      "Epoch: [2][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.1224(0.1256) LR: 0.000822  \n",
      "Fold 0 Epoch 2 - avg_train_loss: 0.1256  time: 124s\n",
      "Epoch: [3][0/224] Elapsed 0m 1s (remain 4m 33s) Loss: 0.1477(0.1477) LR: 0.000821  \n",
      "Epoch: [3][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0809(0.1114) LR: 0.000801  \n",
      "Epoch: [3][100/224] Elapsed 0m 55s (remain 1m 8s) Loss: 0.1247(0.1044) LR: 0.000780  \n",
      "Epoch: [3][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0918(0.1066) LR: 0.000760  \n",
      "Epoch: [3][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0929(0.1061) LR: 0.000740  \n",
      "Epoch: [3][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0585(0.1062) LR: 0.000730  \n",
      "Fold 0 Epoch 3 - avg_train_loss: 0.1062  time: 124s\n",
      "Epoch: [4][0/224] Elapsed 0m 1s (remain 4m 58s) Loss: 0.0838(0.0838) LR: 0.000730  \n",
      "Epoch: [4][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.1511(0.1091) LR: 0.000709  \n",
      "Epoch: [4][100/224] Elapsed 0m 57s (remain 1m 9s) Loss: 0.0987(0.1042) LR: 0.000689  \n",
      "Epoch: [4][150/224] Elapsed 1m 24s (remain 0m 40s) Loss: 0.1299(0.1013) LR: 0.000669  \n",
      "Epoch: [4][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.1178(0.0956) LR: 0.000648  \n",
      "Epoch: [4][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0890(0.0962) LR: 0.000639  \n",
      "Fold 0 Epoch 4 - avg_train_loss: 0.0962  time: 124s\n",
      "Epoch: [5][0/224] Elapsed 0m 1s (remain 4m 51s) Loss: 0.1213(0.1213) LR: 0.000639  \n",
      "Epoch: [5][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1066(0.0941) LR: 0.000618  \n",
      "Epoch: [5][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0535(0.0908) LR: 0.000598  \n",
      "Epoch: [5][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.1381(0.0884) LR: 0.000577  \n",
      "Epoch: [5][200/224] Elapsed 1m 53s (remain 0m 12s) Loss: 0.0915(0.0907) LR: 0.000557  \n",
      "Epoch: [5][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.0696(0.0899) LR: 0.000548  \n",
      "Fold 0 Epoch 5 - avg_train_loss: 0.0899  time: 127s\n",
      "Epoch: [6][0/224] Elapsed 0m 1s (remain 5m 6s) Loss: 0.1114(0.1114) LR: 0.000547  \n",
      "Epoch: [6][50/224] Elapsed 0m 30s (remain 1m 44s) Loss: 0.0775(0.0897) LR: 0.000527  \n",
      "Epoch: [6][100/224] Elapsed 0m 57s (remain 1m 10s) Loss: 0.1015(0.0846) LR: 0.000507  \n",
      "Epoch: [6][150/224] Elapsed 1m 24s (remain 0m 41s) Loss: 0.0536(0.0851) LR: 0.000486  \n",
      "Epoch: [6][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.0814(0.0829) LR: 0.000466  \n",
      "Epoch: [6][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0697(0.0827) LR: 0.000456  \n",
      "Fold 0 Epoch 6 - avg_train_loss: 0.0827  time: 124s\n",
      "Epoch: [7][0/224] Elapsed 0m 1s (remain 4m 38s) Loss: 0.0879(0.0879) LR: 0.000456  \n",
      "Epoch: [7][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0706(0.0739) LR: 0.000436  \n",
      "Epoch: [7][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0591(0.0740) LR: 0.000415  \n",
      "Epoch: [7][150/224] Elapsed 1m 21s (remain 0m 39s) Loss: 0.0962(0.0737) LR: 0.000395  \n",
      "Epoch: [7][200/224] Elapsed 1m 48s (remain 0m 12s) Loss: 0.0857(0.0752) LR: 0.000374  \n",
      "Epoch: [7][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0335(0.0749) LR: 0.000365  \n",
      "Fold 0 Epoch 7 - avg_train_loss: 0.0749  time: 121s\n",
      "Epoch: [8][0/224] Elapsed 0m 1s (remain 4m 54s) Loss: 0.0270(0.0270) LR: 0.000365  \n",
      "Epoch: [8][50/224] Elapsed 0m 29s (remain 1m 38s) Loss: 0.0934(0.0743) LR: 0.000344  \n",
      "Epoch: [8][100/224] Elapsed 0m 56s (remain 1m 8s) Loss: 0.0497(0.0741) LR: 0.000324  \n",
      "Epoch: [8][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0758(0.0732) LR: 0.000304  \n",
      "Epoch: [8][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0610(0.0721) LR: 0.000283  \n",
      "Epoch: [8][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1110(0.0713) LR: 0.000274  \n",
      "Fold 0 Epoch 8 - avg_train_loss: 0.0713  time: 123s\n",
      "Epoch: [9][0/224] Elapsed 0m 1s (remain 5m 10s) Loss: 0.0686(0.0686) LR: 0.000273  \n",
      "Epoch: [9][50/224] Elapsed 0m 30s (remain 1m 41s) Loss: 0.1049(0.0668) LR: 0.000253  \n",
      "Epoch: [9][100/224] Elapsed 0m 57s (remain 1m 9s) Loss: 0.0708(0.0653) LR: 0.000233  \n",
      "Epoch: [9][150/224] Elapsed 1m 24s (remain 0m 40s) Loss: 0.1257(0.0643) LR: 0.000212  \n",
      "Epoch: [9][200/224] Elapsed 1m 53s (remain 0m 12s) Loss: 0.0712(0.0643) LR: 0.000192  \n",
      "Epoch: [9][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.0413(0.0649) LR: 0.000183  \n",
      "Fold 0 Epoch 9 - avg_train_loss: 0.0649  time: 126s\n",
      "Epoch: [10][0/224] Elapsed 0m 1s (remain 4m 51s) Loss: 0.0729(0.0729) LR: 0.000182  \n",
      "Epoch: [10][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0425(0.0617) LR: 0.000162  \n",
      "Epoch: [10][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0643(0.0600) LR: 0.000141  \n",
      "Epoch: [10][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0283(0.0597) LR: 0.000121  \n",
      "Epoch: [10][200/224] Elapsed 1m 53s (remain 0m 12s) Loss: 0.0417(0.0614) LR: 0.000101  \n",
      "Epoch: [10][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.0497(0.0620) LR: 0.000091  \n",
      "Fold 0 Epoch 10 - avg_train_loss: 0.0620  time: 127s\n",
      "Epoch: [11][0/224] Elapsed 0m 1s (remain 4m 49s) Loss: 0.0435(0.0435) LR: 0.000091  \n",
      "Epoch: [11][50/224] Elapsed 0m 30s (remain 1m 44s) Loss: 0.0380(0.0582) LR: 0.000070  \n",
      "Epoch: [11][100/224] Elapsed 0m 58s (remain 1m 10s) Loss: 0.0772(0.0602) LR: 0.000050  \n",
      "Epoch: [11][150/224] Elapsed 1m 26s (remain 0m 41s) Loss: 0.0561(0.0586) LR: 0.000030  \n",
      "Epoch: [11][200/224] Elapsed 1m 53s (remain 0m 12s) Loss: 0.0419(0.0586) LR: 0.000009  \n",
      "Epoch: [11][223/224] Elapsed 2m 5s (remain 0m 0s) Loss: 0.0671(0.0581) LR: 0.000000  \n",
      "Fold 0 Epoch 11 - avg_train_loss: 0.0581  time: 126s\n",
      "========== fold 1 training ==========\n",
      "Train Size: 5369\n",
      "Epoch: [1][0/224] Elapsed 0m 1s (remain 4m 40s) Loss: 0.7399(0.7399) LR: 0.000100  \n",
      "Epoch: [1][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.1587(0.2426) LR: 0.000983  \n",
      "Epoch: [1][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.2286(0.2045) LR: 0.000963  \n",
      "Epoch: [1][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.1112(0.1863) LR: 0.000943  \n",
      "Epoch: [1][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.1332(0.1750) LR: 0.000922  \n",
      "Epoch: [1][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1597(0.1704) LR: 0.000913  \n",
      "Fold 1 Epoch 1 - avg_train_loss: 0.1704  time: 123s\n",
      "Epoch: [2][0/224] Elapsed 0m 1s (remain 5m 4s) Loss: 0.1372(0.1372) LR: 0.000912  \n",
      "Epoch: [2][50/224] Elapsed 0m 28s (remain 1m 38s) Loss: 0.1386(0.1323) LR: 0.000892  \n",
      "Epoch: [2][100/224] Elapsed 0m 55s (remain 1m 8s) Loss: 0.1571(0.1334) LR: 0.000872  \n",
      "Epoch: [2][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.1403(0.1300) LR: 0.000851  \n",
      "Epoch: [2][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0960(0.1260) LR: 0.000831  \n",
      "Epoch: [2][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0741(0.1250) LR: 0.000822  \n",
      "Fold 1 Epoch 2 - avg_train_loss: 0.1250  time: 122s\n",
      "Epoch: [3][0/224] Elapsed 0m 1s (remain 4m 54s) Loss: 0.2247(0.2247) LR: 0.000821  \n",
      "Epoch: [3][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1343(0.1225) LR: 0.000801  \n",
      "Epoch: [3][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0759(0.1161) LR: 0.000780  \n",
      "Epoch: [3][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0929(0.1131) LR: 0.000760  \n",
      "Epoch: [3][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0979(0.1108) LR: 0.000740  \n",
      "Epoch: [3][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.1380(0.1090) LR: 0.000730  \n",
      "Fold 1 Epoch 3 - avg_train_loss: 0.1090  time: 122s\n",
      "Epoch: [4][0/224] Elapsed 0m 1s (remain 4m 48s) Loss: 0.0458(0.0458) LR: 0.000730  \n",
      "Epoch: [4][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1047(0.1028) LR: 0.000709  \n",
      "Epoch: [4][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1120(0.1009) LR: 0.000689  \n",
      "Epoch: [4][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0449(0.1050) LR: 0.000669  \n",
      "Epoch: [4][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.1002(0.1018) LR: 0.000648  \n",
      "Epoch: [4][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1346(0.0994) LR: 0.000639  \n",
      "Fold 1 Epoch 4 - avg_train_loss: 0.0994  time: 122s\n",
      "Epoch: [5][0/224] Elapsed 0m 1s (remain 4m 48s) Loss: 0.0899(0.0899) LR: 0.000639  \n",
      "Epoch: [5][50/224] Elapsed 0m 31s (remain 1m 45s) Loss: 0.0638(0.0862) LR: 0.000618  \n",
      "Epoch: [5][100/224] Elapsed 0m 58s (remain 1m 11s) Loss: 0.1152(0.0845) LR: 0.000598  \n",
      "Epoch: [5][150/224] Elapsed 1m 25s (remain 0m 41s) Loss: 0.0844(0.0854) LR: 0.000577  \n",
      "Epoch: [5][200/224] Elapsed 1m 52s (remain 0m 12s) Loss: 0.1050(0.0882) LR: 0.000557  \n",
      "Epoch: [5][223/224] Elapsed 2m 5s (remain 0m 0s) Loss: 0.1205(0.0889) LR: 0.000548  \n",
      "Fold 1 Epoch 5 - avg_train_loss: 0.0889  time: 126s\n",
      "Epoch: [6][0/224] Elapsed 0m 1s (remain 5m 1s) Loss: 0.0285(0.0285) LR: 0.000547  \n",
      "Epoch: [6][50/224] Elapsed 0m 28s (remain 1m 38s) Loss: 0.0623(0.0793) LR: 0.000527  \n",
      "Epoch: [6][100/224] Elapsed 0m 56s (remain 1m 9s) Loss: 0.0676(0.0812) LR: 0.000507  \n",
      "Epoch: [6][150/224] Elapsed 1m 26s (remain 0m 42s) Loss: 0.0978(0.0838) LR: 0.000486  \n",
      "Epoch: [6][200/224] Elapsed 1m 55s (remain 0m 13s) Loss: 0.0549(0.0819) LR: 0.000466  \n",
      "Epoch: [6][223/224] Elapsed 2m 7s (remain 0m 0s) Loss: 0.0437(0.0812) LR: 0.000456  \n",
      "Fold 1 Epoch 6 - avg_train_loss: 0.0812  time: 128s\n",
      "Epoch: [7][0/224] Elapsed 0m 1s (remain 4m 54s) Loss: 0.0378(0.0378) LR: 0.000456  \n",
      "Epoch: [7][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0462(0.0737) LR: 0.000436  \n",
      "Epoch: [7][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0905(0.0744) LR: 0.000415  \n",
      "Epoch: [7][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.0248(0.0734) LR: 0.000395  \n",
      "Epoch: [7][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0958(0.0770) LR: 0.000374  \n",
      "Epoch: [7][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0393(0.0768) LR: 0.000365  \n",
      "Fold 1 Epoch 7 - avg_train_loss: 0.0768  time: 122s\n",
      "Epoch: [8][0/224] Elapsed 0m 1s (remain 4m 34s) Loss: 0.0513(0.0513) LR: 0.000365  \n",
      "Epoch: [8][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0341(0.0710) LR: 0.000344  \n",
      "Epoch: [8][100/224] Elapsed 0m 57s (remain 1m 9s) Loss: 0.0833(0.0706) LR: 0.000324  \n",
      "Epoch: [8][150/224] Elapsed 1m 26s (remain 0m 41s) Loss: 0.1184(0.0716) LR: 0.000304  \n",
      "Epoch: [8][200/224] Elapsed 1m 54s (remain 0m 13s) Loss: 0.0692(0.0708) LR: 0.000283  \n",
      "Epoch: [8][223/224] Elapsed 2m 7s (remain 0m 0s) Loss: 0.0601(0.0701) LR: 0.000274  \n",
      "Fold 1 Epoch 8 - avg_train_loss: 0.0701  time: 127s\n",
      "Epoch: [9][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0514(0.0514) LR: 0.000273  \n",
      "Epoch: [9][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0660(0.0662) LR: 0.000253  \n",
      "Epoch: [9][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1203(0.0675) LR: 0.000233  \n",
      "Epoch: [9][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.0372(0.0661) LR: 0.000212  \n",
      "Epoch: [9][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0659(0.0650) LR: 0.000192  \n",
      "Epoch: [9][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1064(0.0647) LR: 0.000183  \n",
      "Fold 1 Epoch 9 - avg_train_loss: 0.0647  time: 122s\n",
      "Epoch: [10][0/224] Elapsed 0m 1s (remain 4m 42s) Loss: 0.0546(0.0546) LR: 0.000182  \n",
      "Epoch: [10][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0298(0.0622) LR: 0.000162  \n",
      "Epoch: [10][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0664(0.0637) LR: 0.000141  \n",
      "Epoch: [10][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0826(0.0620) LR: 0.000121  \n",
      "Epoch: [10][200/224] Elapsed 1m 48s (remain 0m 12s) Loss: 0.0576(0.0601) LR: 0.000101  \n",
      "Epoch: [10][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0430(0.0606) LR: 0.000091  \n",
      "Fold 1 Epoch 10 - avg_train_loss: 0.0606  time: 121s\n",
      "Epoch: [11][0/224] Elapsed 0m 1s (remain 4m 53s) Loss: 0.0320(0.0320) LR: 0.000091  \n",
      "Epoch: [11][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0521(0.0576) LR: 0.000070  \n",
      "Epoch: [11][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0253(0.0587) LR: 0.000050  \n",
      "Epoch: [11][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0549(0.0586) LR: 0.000030  \n",
      "Epoch: [11][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.0574(0.0585) LR: 0.000009  \n",
      "Epoch: [11][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0318(0.0581) LR: 0.000000  \n",
      "Fold 1 Epoch 11 - avg_train_loss: 0.0581  time: 124s\n",
      "========== fold 2 training ==========\n",
      "Train Size: 5369\n",
      "Epoch: [1][0/224] Elapsed 0m 1s (remain 4m 49s) Loss: 0.6804(0.6804) LR: 0.000100  \n",
      "Epoch: [1][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0921(0.2348) LR: 0.000983  \n",
      "Epoch: [1][100/224] Elapsed 0m 55s (remain 1m 8s) Loss: 0.0904(0.2006) LR: 0.000963  \n",
      "Epoch: [1][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.1164(0.1808) LR: 0.000943  \n",
      "Epoch: [1][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.1205(0.1700) LR: 0.000922  \n",
      "Epoch: [1][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.1285(0.1673) LR: 0.000913  \n",
      "Fold 2 Epoch 1 - avg_train_loss: 0.1673  time: 124s\n",
      "Epoch: [2][0/224] Elapsed 0m 1s (remain 4m 51s) Loss: 0.2110(0.2110) LR: 0.000912  \n",
      "Epoch: [2][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0542(0.1295) LR: 0.000892  \n",
      "Epoch: [2][100/224] Elapsed 0m 57s (remain 1m 10s) Loss: 0.0642(0.1222) LR: 0.000872  \n",
      "Epoch: [2][150/224] Elapsed 1m 27s (remain 0m 42s) Loss: 0.1715(0.1204) LR: 0.000851  \n",
      "Epoch: [2][200/224] Elapsed 1m 54s (remain 0m 13s) Loss: 0.1124(0.1199) LR: 0.000831  \n",
      "Epoch: [2][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.1138(0.1208) LR: 0.000822  \n",
      "Fold 2 Epoch 2 - avg_train_loss: 0.1208  time: 127s\n",
      "Epoch: [3][0/224] Elapsed 0m 1s (remain 4m 50s) Loss: 0.0878(0.0878) LR: 0.000821  \n",
      "Epoch: [3][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0837(0.1081) LR: 0.000801  \n",
      "Epoch: [3][100/224] Elapsed 0m 55s (remain 1m 8s) Loss: 0.0908(0.1079) LR: 0.000780  \n",
      "Epoch: [3][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.1103(0.1087) LR: 0.000760  \n",
      "Epoch: [3][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0872(0.1081) LR: 0.000740  \n",
      "Epoch: [3][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0243(0.1083) LR: 0.000730  \n",
      "Fold 2 Epoch 3 - avg_train_loss: 0.1083  time: 123s\n",
      "Epoch: [4][0/224] Elapsed 0m 1s (remain 4m 47s) Loss: 0.1407(0.1407) LR: 0.000730  \n",
      "Epoch: [4][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0845(0.1013) LR: 0.000709  \n",
      "Epoch: [4][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0638(0.1015) LR: 0.000689  \n",
      "Epoch: [4][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.1054(0.1039) LR: 0.000669  \n",
      "Epoch: [4][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0543(0.1020) LR: 0.000648  \n",
      "Epoch: [4][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0586(0.1018) LR: 0.000639  \n",
      "Fold 2 Epoch 4 - avg_train_loss: 0.1018  time: 122s\n",
      "Epoch: [5][0/224] Elapsed 0m 1s (remain 5m 2s) Loss: 0.1576(0.1576) LR: 0.000639  \n",
      "Epoch: [5][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.1437(0.0879) LR: 0.000618  \n",
      "Epoch: [5][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1543(0.0907) LR: 0.000598  \n",
      "Epoch: [5][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0283(0.0920) LR: 0.000577  \n",
      "Epoch: [5][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.1055(0.0893) LR: 0.000557  \n",
      "Epoch: [5][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0608(0.0885) LR: 0.000548  \n",
      "Fold 2 Epoch 5 - avg_train_loss: 0.0885  time: 124s\n",
      "Epoch: [6][0/224] Elapsed 0m 1s (remain 4m 56s) Loss: 0.1167(0.1167) LR: 0.000547  \n",
      "Epoch: [6][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0913(0.0811) LR: 0.000527  \n",
      "Epoch: [6][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0490(0.0836) LR: 0.000507  \n",
      "Epoch: [6][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.1135(0.0830) LR: 0.000486  \n",
      "Epoch: [6][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0966(0.0820) LR: 0.000466  \n",
      "Epoch: [6][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1405(0.0826) LR: 0.000456  \n",
      "Fold 2 Epoch 6 - avg_train_loss: 0.0826  time: 123s\n",
      "Epoch: [7][0/224] Elapsed 0m 1s (remain 4m 46s) Loss: 0.0610(0.0610) LR: 0.000456  \n",
      "Epoch: [7][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0910(0.0810) LR: 0.000436  \n",
      "Epoch: [7][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0535(0.0775) LR: 0.000415  \n",
      "Epoch: [7][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0602(0.0757) LR: 0.000395  \n",
      "Epoch: [7][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0929(0.0749) LR: 0.000374  \n",
      "Epoch: [7][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0544(0.0754) LR: 0.000365  \n",
      "Fold 2 Epoch 7 - avg_train_loss: 0.0754  time: 122s\n",
      "Epoch: [8][0/224] Elapsed 0m 1s (remain 4m 48s) Loss: 0.1451(0.1451) LR: 0.000365  \n",
      "Epoch: [8][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0359(0.0693) LR: 0.000344  \n",
      "Epoch: [8][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0432(0.0656) LR: 0.000324  \n",
      "Epoch: [8][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0921(0.0662) LR: 0.000304  \n",
      "Epoch: [8][200/224] Elapsed 1m 48s (remain 0m 12s) Loss: 0.0986(0.0677) LR: 0.000283  \n",
      "Epoch: [8][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.1614(0.0686) LR: 0.000274  \n",
      "Fold 2 Epoch 8 - avg_train_loss: 0.0686  time: 121s\n",
      "Epoch: [9][0/224] Elapsed 0m 1s (remain 4m 47s) Loss: 0.0455(0.0455) LR: 0.000273  \n",
      "Epoch: [9][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0411(0.0670) LR: 0.000253  \n",
      "Epoch: [9][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0457(0.0634) LR: 0.000233  \n",
      "Epoch: [9][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0728(0.0642) LR: 0.000212  \n",
      "Epoch: [9][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0080(0.0639) LR: 0.000192  \n",
      "Epoch: [9][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0514(0.0647) LR: 0.000183  \n",
      "Fold 2 Epoch 9 - avg_train_loss: 0.0647  time: 122s\n",
      "Epoch: [10][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0461(0.0461) LR: 0.000182  \n",
      "Epoch: [10][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0977(0.0625) LR: 0.000162  \n",
      "Epoch: [10][100/224] Elapsed 0m 56s (remain 1m 8s) Loss: 0.0617(0.0638) LR: 0.000141  \n",
      "Epoch: [10][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0640(0.0612) LR: 0.000121  \n",
      "Epoch: [10][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.0639(0.0612) LR: 0.000101  \n",
      "Epoch: [10][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0655(0.0601) LR: 0.000091  \n",
      "Fold 2 Epoch 10 - avg_train_loss: 0.0601  time: 124s\n",
      "Epoch: [11][0/224] Elapsed 0m 1s (remain 4m 50s) Loss: 0.0784(0.0784) LR: 0.000091  \n",
      "Epoch: [11][50/224] Elapsed 0m 30s (remain 1m 44s) Loss: 0.0535(0.0584) LR: 0.000070  \n",
      "Epoch: [11][100/224] Elapsed 0m 59s (remain 1m 12s) Loss: 0.0411(0.0565) LR: 0.000050  \n",
      "Epoch: [11][150/224] Elapsed 1m 26s (remain 0m 42s) Loss: 0.0726(0.0574) LR: 0.000030  \n",
      "Epoch: [11][200/224] Elapsed 1m 54s (remain 0m 13s) Loss: 0.0592(0.0573) LR: 0.000009  \n",
      "Epoch: [11][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.0124(0.0576) LR: 0.000000  \n",
      "Fold 2 Epoch 11 - avg_train_loss: 0.0576  time: 127s\n",
      "========== fold 3 training ==========\n",
      "Train Size: 5369\n",
      "Epoch: [1][0/224] Elapsed 0m 1s (remain 4m 50s) Loss: 0.7555(0.7555) LR: 0.000100  \n",
      "Epoch: [1][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1385(0.2408) LR: 0.000983  \n",
      "Epoch: [1][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1240(0.2040) LR: 0.000963  \n",
      "Epoch: [1][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.1335(0.1893) LR: 0.000943  \n",
      "Epoch: [1][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.1535(0.1761) LR: 0.000922  \n",
      "Epoch: [1][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.1102(0.1708) LR: 0.000913  \n",
      "Fold 3 Epoch 1 - avg_train_loss: 0.1708  time: 122s\n",
      "Epoch: [2][0/224] Elapsed 0m 1s (remain 4m 52s) Loss: 0.1286(0.1286) LR: 0.000912  \n",
      "Epoch: [2][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0846(0.1276) LR: 0.000892  \n",
      "Epoch: [2][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1891(0.1327) LR: 0.000872  \n",
      "Epoch: [2][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.1632(0.1266) LR: 0.000851  \n",
      "Epoch: [2][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.2071(0.1232) LR: 0.000831  \n",
      "Epoch: [2][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.1074(0.1215) LR: 0.000822  \n",
      "Fold 3 Epoch 2 - avg_train_loss: 0.1215  time: 122s\n",
      "Epoch: [3][0/224] Elapsed 0m 1s (remain 4m 45s) Loss: 0.0871(0.0871) LR: 0.000821  \n",
      "Epoch: [3][50/224] Elapsed 0m 30s (remain 1m 44s) Loss: 0.1184(0.1127) LR: 0.000801  \n",
      "Epoch: [3][100/224] Elapsed 0m 58s (remain 1m 10s) Loss: 0.0510(0.1157) LR: 0.000780  \n",
      "Epoch: [3][150/224] Elapsed 1m 25s (remain 0m 41s) Loss: 0.1044(0.1126) LR: 0.000760  \n",
      "Epoch: [3][200/224] Elapsed 1m 53s (remain 0m 12s) Loss: 0.1543(0.1099) LR: 0.000740  \n",
      "Epoch: [3][223/224] Elapsed 2m 6s (remain 0m 0s) Loss: 0.0825(0.1095) LR: 0.000730  \n",
      "Fold 3 Epoch 3 - avg_train_loss: 0.1095  time: 126s\n",
      "Epoch: [4][0/224] Elapsed 0m 1s (remain 4m 51s) Loss: 0.1759(0.1759) LR: 0.000730  \n",
      "Epoch: [4][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.1476(0.1011) LR: 0.000709  \n",
      "Epoch: [4][100/224] Elapsed 0m 56s (remain 1m 8s) Loss: 0.1095(0.0993) LR: 0.000689  \n",
      "Epoch: [4][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0985(0.0972) LR: 0.000669  \n",
      "Epoch: [4][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0748(0.0944) LR: 0.000648  \n",
      "Epoch: [4][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0872(0.0957) LR: 0.000639  \n",
      "Fold 3 Epoch 4 - avg_train_loss: 0.0957  time: 124s\n",
      "Epoch: [5][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0863(0.0863) LR: 0.000639  \n",
      "Epoch: [5][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0978(0.0905) LR: 0.000618  \n",
      "Epoch: [5][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1178(0.0896) LR: 0.000598  \n",
      "Epoch: [5][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0540(0.0861) LR: 0.000577  \n",
      "Epoch: [5][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0396(0.0839) LR: 0.000557  \n",
      "Epoch: [5][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.1026(0.0842) LR: 0.000548  \n",
      "Fold 3 Epoch 5 - avg_train_loss: 0.0842  time: 122s\n",
      "Epoch: [6][0/224] Elapsed 0m 1s (remain 4m 17s) Loss: 0.0393(0.0393) LR: 0.000547  \n",
      "Epoch: [6][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0999(0.0833) LR: 0.000527  \n",
      "Epoch: [6][100/224] Elapsed 0m 54s (remain 1m 6s) Loss: 0.0752(0.0816) LR: 0.000507  \n",
      "Epoch: [6][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0434(0.0797) LR: 0.000486  \n",
      "Epoch: [6][200/224] Elapsed 1m 48s (remain 0m 12s) Loss: 0.0674(0.0803) LR: 0.000466  \n",
      "Epoch: [6][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0977(0.0795) LR: 0.000456  \n",
      "Fold 3 Epoch 6 - avg_train_loss: 0.0795  time: 121s\n",
      "Epoch: [7][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0737(0.0737) LR: 0.000456  \n",
      "Epoch: [7][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0923(0.0757) LR: 0.000436  \n",
      "Epoch: [7][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1108(0.0747) LR: 0.000415  \n",
      "Epoch: [7][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.1129(0.0721) LR: 0.000395  \n",
      "Epoch: [7][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0847(0.0719) LR: 0.000374  \n",
      "Epoch: [7][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0503(0.0725) LR: 0.000365  \n",
      "Fold 3 Epoch 7 - avg_train_loss: 0.0725  time: 123s\n",
      "Epoch: [8][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0190(0.0190) LR: 0.000365  \n",
      "Epoch: [8][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0925(0.0678) LR: 0.000344  \n",
      "Epoch: [8][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0682(0.0670) LR: 0.000324  \n",
      "Epoch: [8][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0481(0.0665) LR: 0.000304  \n",
      "Epoch: [8][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0456(0.0676) LR: 0.000283  \n",
      "Epoch: [8][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0956(0.0676) LR: 0.000274  \n",
      "Fold 3 Epoch 8 - avg_train_loss: 0.0676  time: 122s\n",
      "Epoch: [9][0/224] Elapsed 0m 1s (remain 5m 14s) Loss: 0.0905(0.0905) LR: 0.000273  \n",
      "Epoch: [9][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1022(0.0676) LR: 0.000253  \n",
      "Epoch: [9][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0795(0.0647) LR: 0.000233  \n",
      "Epoch: [9][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0745(0.0648) LR: 0.000212  \n",
      "Epoch: [9][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0964(0.0639) LR: 0.000192  \n",
      "Epoch: [9][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0358(0.0634) LR: 0.000183  \n",
      "Fold 3 Epoch 9 - avg_train_loss: 0.0634  time: 121s\n",
      "Epoch: [10][0/224] Elapsed 0m 1s (remain 4m 48s) Loss: 0.0861(0.0861) LR: 0.000182  \n",
      "Epoch: [10][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0473(0.0604) LR: 0.000162  \n",
      "Epoch: [10][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0704(0.0590) LR: 0.000141  \n",
      "Epoch: [10][150/224] Elapsed 1m 22s (remain 0m 40s) Loss: 0.0587(0.0592) LR: 0.000121  \n",
      "Epoch: [10][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0681(0.0590) LR: 0.000101  \n",
      "Epoch: [10][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0644(0.0583) LR: 0.000091  \n",
      "Fold 3 Epoch 10 - avg_train_loss: 0.0583  time: 123s\n",
      "Epoch: [11][0/224] Elapsed 0m 1s (remain 4m 52s) Loss: 0.0523(0.0523) LR: 0.000091  \n",
      "Epoch: [11][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0304(0.0559) LR: 0.000070  \n",
      "Epoch: [11][100/224] Elapsed 0m 58s (remain 1m 10s) Loss: 0.0393(0.0557) LR: 0.000050  \n",
      "Epoch: [11][150/224] Elapsed 1m 25s (remain 0m 41s) Loss: 0.0644(0.0560) LR: 0.000030  \n",
      "Epoch: [11][200/224] Elapsed 1m 52s (remain 0m 12s) Loss: 0.0422(0.0544) LR: 0.000009  \n",
      "Epoch: [11][223/224] Elapsed 2m 5s (remain 0m 0s) Loss: 0.0115(0.0550) LR: 0.000000  \n",
      "Fold 3 Epoch 11 - avg_train_loss: 0.0550  time: 125s\n",
      "========== fold 4 training ==========\n",
      "Train Size: 5369\n",
      "Epoch: [1][0/224] Elapsed 0m 1s (remain 5m 10s) Loss: 0.7180(0.7180) LR: 0.000100  \n",
      "Epoch: [1][50/224] Elapsed 0m 30s (remain 1m 43s) Loss: 0.0985(0.2384) LR: 0.000983  \n",
      "Epoch: [1][100/224] Elapsed 0m 57s (remain 1m 10s) Loss: 0.1354(0.2033) LR: 0.000963  \n",
      "Epoch: [1][150/224] Elapsed 1m 24s (remain 0m 41s) Loss: 0.2747(0.1873) LR: 0.000943  \n",
      "Epoch: [1][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.1355(0.1755) LR: 0.000922  \n",
      "Epoch: [1][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.1686(0.1704) LR: 0.000913  \n",
      "Fold 4 Epoch 1 - avg_train_loss: 0.1704  time: 124s\n",
      "Epoch: [2][0/224] Elapsed 0m 1s (remain 4m 46s) Loss: 0.1011(0.1011) LR: 0.000912  \n",
      "Epoch: [2][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.0971(0.1238) LR: 0.000892  \n",
      "Epoch: [2][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1360(0.1271) LR: 0.000872  \n",
      "Epoch: [2][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.1408(0.1312) LR: 0.000851  \n",
      "Epoch: [2][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.1822(0.1277) LR: 0.000831  \n",
      "Epoch: [2][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0956(0.1246) LR: 0.000822  \n",
      "Fold 4 Epoch 2 - avg_train_loss: 0.1246  time: 121s\n",
      "Epoch: [3][0/224] Elapsed 0m 1s (remain 4m 40s) Loss: 0.1095(0.1095) LR: 0.000821  \n",
      "Epoch: [3][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.1646(0.1069) LR: 0.000801  \n",
      "Epoch: [3][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.1184(0.1080) LR: 0.000780  \n",
      "Epoch: [3][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.1011(0.1079) LR: 0.000760  \n",
      "Epoch: [3][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0587(0.1081) LR: 0.000740  \n",
      "Epoch: [3][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0821(0.1061) LR: 0.000730  \n",
      "Fold 4 Epoch 3 - avg_train_loss: 0.1061  time: 123s\n",
      "Epoch: [4][0/224] Elapsed 0m 1s (remain 5m 1s) Loss: 0.1009(0.1009) LR: 0.000730  \n",
      "Epoch: [4][50/224] Elapsed 0m 28s (remain 1m 36s) Loss: 0.1455(0.0899) LR: 0.000709  \n",
      "Epoch: [4][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0682(0.0926) LR: 0.000689  \n",
      "Epoch: [4][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0386(0.0944) LR: 0.000669  \n",
      "Epoch: [4][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0717(0.0924) LR: 0.000648  \n",
      "Epoch: [4][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0576(0.0928) LR: 0.000639  \n",
      "Fold 4 Epoch 4 - avg_train_loss: 0.0928  time: 122s\n",
      "Epoch: [5][0/224] Elapsed 0m 1s (remain 4m 46s) Loss: 0.0484(0.0484) LR: 0.000639  \n",
      "Epoch: [5][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.0586(0.0859) LR: 0.000618  \n",
      "Epoch: [5][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0846(0.0844) LR: 0.000598  \n",
      "Epoch: [5][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0380(0.0857) LR: 0.000577  \n",
      "Epoch: [5][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0427(0.0861) LR: 0.000557  \n",
      "Epoch: [5][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0395(0.0860) LR: 0.000548  \n",
      "Fold 4 Epoch 5 - avg_train_loss: 0.0860  time: 123s\n",
      "Epoch: [6][0/224] Elapsed 0m 1s (remain 4m 48s) Loss: 0.1112(0.1112) LR: 0.000547  \n",
      "Epoch: [6][50/224] Elapsed 0m 28s (remain 1m 37s) Loss: 0.1021(0.0752) LR: 0.000527  \n",
      "Epoch: [6][100/224] Elapsed 0m 56s (remain 1m 9s) Loss: 0.0486(0.0763) LR: 0.000507  \n",
      "Epoch: [6][150/224] Elapsed 1m 24s (remain 0m 40s) Loss: 0.0802(0.0781) LR: 0.000486  \n",
      "Epoch: [6][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.1309(0.0797) LR: 0.000466  \n",
      "Epoch: [6][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0674(0.0796) LR: 0.000456  \n",
      "Fold 4 Epoch 6 - avg_train_loss: 0.0796  time: 124s\n",
      "Epoch: [7][0/224] Elapsed 0m 1s (remain 4m 55s) Loss: 0.0502(0.0502) LR: 0.000456  \n",
      "Epoch: [7][50/224] Elapsed 0m 30s (remain 1m 41s) Loss: 0.0830(0.0666) LR: 0.000436  \n",
      "Epoch: [7][100/224] Elapsed 0m 57s (remain 1m 9s) Loss: 0.0792(0.0708) LR: 0.000415  \n",
      "Epoch: [7][150/224] Elapsed 1m 24s (remain 0m 40s) Loss: 0.0926(0.0688) LR: 0.000395  \n",
      "Epoch: [7][200/224] Elapsed 1m 51s (remain 0m 12s) Loss: 0.0635(0.0708) LR: 0.000374  \n",
      "Epoch: [7][223/224] Elapsed 2m 4s (remain 0m 0s) Loss: 0.0667(0.0718) LR: 0.000365  \n",
      "Fold 4 Epoch 7 - avg_train_loss: 0.0718  time: 124s\n",
      "Epoch: [8][0/224] Elapsed 0m 1s (remain 4m 52s) Loss: 0.0513(0.0513) LR: 0.000365  \n",
      "Epoch: [8][50/224] Elapsed 0m 28s (remain 1m 35s) Loss: 0.0953(0.0722) LR: 0.000344  \n",
      "Epoch: [8][100/224] Elapsed 0m 55s (remain 1m 7s) Loss: 0.0561(0.0698) LR: 0.000324  \n",
      "Epoch: [8][150/224] Elapsed 1m 22s (remain 0m 39s) Loss: 0.0498(0.0687) LR: 0.000304  \n",
      "Epoch: [8][200/224] Elapsed 1m 49s (remain 0m 12s) Loss: 0.0607(0.0674) LR: 0.000283  \n",
      "Epoch: [8][223/224] Elapsed 2m 1s (remain 0m 0s) Loss: 0.0550(0.0665) LR: 0.000274  \n",
      "Fold 4 Epoch 8 - avg_train_loss: 0.0665  time: 122s\n",
      "Epoch: [9][0/224] Elapsed 0m 1s (remain 4m 39s) Loss: 0.0465(0.0465) LR: 0.000273  \n",
      "Epoch: [9][50/224] Elapsed 0m 29s (remain 1m 39s) Loss: 0.1073(0.0586) LR: 0.000253  \n",
      "Epoch: [9][100/224] Elapsed 0m 56s (remain 1m 8s) Loss: 0.0335(0.0591) LR: 0.000233  \n",
      "Epoch: [9][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0493(0.0607) LR: 0.000212  \n",
      "Epoch: [9][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0029(0.0610) LR: 0.000192  \n",
      "Epoch: [9][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0387(0.0615) LR: 0.000183  \n",
      "Fold 4 Epoch 9 - avg_train_loss: 0.0615  time: 123s\n",
      "Epoch: [10][0/224] Elapsed 0m 1s (remain 5m 1s) Loss: 0.0407(0.0407) LR: 0.000182  \n",
      "Epoch: [10][50/224] Elapsed 0m 30s (remain 1m 42s) Loss: 0.0925(0.0638) LR: 0.000162  \n",
      "Epoch: [10][100/224] Elapsed 0m 57s (remain 1m 9s) Loss: 0.0956(0.0590) LR: 0.000141  \n",
      "Epoch: [10][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0484(0.0587) LR: 0.000121  \n",
      "Epoch: [10][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0462(0.0576) LR: 0.000101  \n",
      "Epoch: [10][223/224] Elapsed 2m 3s (remain 0m 0s) Loss: 0.0621(0.0576) LR: 0.000091  \n",
      "Fold 4 Epoch 10 - avg_train_loss: 0.0576  time: 123s\n",
      "Epoch: [11][0/224] Elapsed 0m 1s (remain 4m 56s) Loss: 0.0234(0.0234) LR: 0.000091  \n",
      "Epoch: [11][50/224] Elapsed 0m 29s (remain 1m 39s) Loss: 0.0923(0.0525) LR: 0.000070  \n",
      "Epoch: [11][100/224] Elapsed 0m 56s (remain 1m 8s) Loss: 0.0309(0.0529) LR: 0.000050  \n",
      "Epoch: [11][150/224] Elapsed 1m 23s (remain 0m 40s) Loss: 0.0622(0.0530) LR: 0.000030  \n",
      "Epoch: [11][200/224] Elapsed 1m 50s (remain 0m 12s) Loss: 0.0717(0.0534) LR: 0.000009  \n",
      "Epoch: [11][223/224] Elapsed 2m 2s (remain 0m 0s) Loss: 0.0637(0.0536) LR: 0.000000  \n",
      "Fold 4 Epoch 11 - avg_train_loss: 0.0536  time: 123s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6e01644-f4a4-4340-837a-8645781ea7a4",
   "metadata": {
    "id": "c6e01644-f4a4-4340-837a-8645781ea7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../mnt/output/pd-exp222\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Starting upload for file fold0_best.pth\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.13 / client 1.5.12)\n",
      "100%|███████████████████████████████████████| 1.83M/1.83M [00:04<00:00, 479kB/s]\n",
      "Upload successful: fold0_best.pth (2MB)\n",
      "Starting upload for file fold1_best.pth\n",
      "100%|███████████████████████████████████████| 1.83M/1.83M [00:02<00:00, 693kB/s]\n",
      "Upload successful: fold1_best.pth (2MB)\n",
      "Starting upload for file fold2_best.pth\n",
      "100%|███████████████████████████████████████| 1.83M/1.83M [00:02<00:00, 729kB/s]\n",
      "Upload successful: fold2_best.pth (2MB)\n",
      "Starting upload for file fold3_best.pth\n",
      "100%|███████████████████████████████████████| 1.83M/1.83M [00:02<00:00, 658kB/s]\n",
      "Upload successful: fold3_best.pth (2MB)\n",
      "Starting upload for file fold4_best.pth\n",
      "100%|███████████████████████████████████████| 1.83M/1.83M [00:03<00:00, 545kB/s]\n",
      "Upload successful: fold4_best.pth (2MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/shuheigoda/pd-exp222\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dataset_metadata_json = {\n",
    "    \"title\": CFG.exp_name,\n",
    "    \"id\": f\"shuheigoda/{CFG.exp_name}\",\n",
    "    \"licenses\": [{\"name\": \"CC0-1.0\"}],\n",
    "}\n",
    "with open(CFG.output_dir / \"dataset-metadata.json\", \"w\") as f:\n",
    "    json.dump(dataset_metadata_json, f, indent=4)\n",
    "t = str(CFG.output_dir)\n",
    "print(t)\n",
    "!kaggle datasets create -p $t -r zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717a6f1-1518-4a4d-8341-040a53ede4cf",
   "metadata": {
    "id": "a717a6f1-1518-4a4d-8341-040a53ede4cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.env == \"colab\":\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bd0eef2f7a413a846e37d368f056f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c855ed2204ed49e58a81ac291790ec3b",
      "placeholder": "​",
      "style": "IPY_MODEL_f68b2dd7986f44dda26d2e4ca9f53d2e",
      "value": "100%"
     }
    },
    "0818ec9dea3d4cd6b4addf3ee0da440e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "260d6bf2013c4108a5aa89f6d60b2cba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "290ce9859be84b79974543b2c57c376e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_01bd0eef2f7a413a846e37d368f056f0",
       "IPY_MODEL_52454b086aaf447c8edb24531ae3667b",
       "IPY_MODEL_3baca38ad56942338ff0bf4edbbb574f"
      ],
      "layout": "IPY_MODEL_74ea4fe086b44b4588b46eca14c05a6a"
     }
    },
    "35cffd00e8cb4bf3b0f878fb1e7fa420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3baca38ad56942338ff0bf4edbbb574f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb182ea1f4094aa9b57a1620371f4999",
      "placeholder": "​",
      "style": "IPY_MODEL_0818ec9dea3d4cd6b4addf3ee0da440e",
      "value": " 91/91 [02:10&lt;00:00,  1.38s/it]"
     }
    },
    "3ddd61aea5da4bebbd0820b5a8dcbc72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e0f016e725074829aafb58bab3b79758",
       "IPY_MODEL_5864b8b070b149a086423fab305123a1",
       "IPY_MODEL_91f29c4b3c4a4daf9175bf86a0e36688"
      ],
      "layout": "IPY_MODEL_c10e37685b474fcaa98370f8534eac49"
     }
    },
    "52454b086aaf447c8edb24531ae3667b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abe4b57c3192493e861fea4ca017742e",
      "max": 91,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35cffd00e8cb4bf3b0f878fb1e7fa420",
      "value": 91
     }
    },
    "5864b8b070b149a086423fab305123a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90656f5109984a10929dc9288162538f",
      "max": 833,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_84688468a6664b46ba24a38ef3628536",
      "value": 833
     }
    },
    "74ea4fe086b44b4588b46eca14c05a6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84688468a6664b46ba24a38ef3628536": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "90656f5109984a10929dc9288162538f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f29c4b3c4a4daf9175bf86a0e36688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9c37afb9a1340d38955572d509c4c27",
      "placeholder": "​",
      "style": "IPY_MODEL_98b5e4d75f004b5bb363fe3a9962a69e",
      "value": " 833/833 [01:17&lt;00:00,  4.41it/s]"
     }
    },
    "98b5e4d75f004b5bb363fe3a9962a69e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9c37afb9a1340d38955572d509c4c27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abe4b57c3192493e861fea4ca017742e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4c24a7c2dbb4ac3afd994a5c9398ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c10e37685b474fcaa98370f8534eac49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c855ed2204ed49e58a81ac291790ec3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0f016e725074829aafb58bab3b79758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_260d6bf2013c4108a5aa89f6d60b2cba",
      "placeholder": "​",
      "style": "IPY_MODEL_b4c24a7c2dbb4ac3afd994a5c9398ccf",
      "value": "100%"
     }
    },
    "eb182ea1f4094aa9b57a1620371f4999": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f68b2dd7986f44dda26d2e4ca9f53d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
